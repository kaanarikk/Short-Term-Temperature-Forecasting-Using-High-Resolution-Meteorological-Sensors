# -*- coding: utf-8 -*-
"""041225burak_sensetech_High_Precision_Weather_Forecasting_with_Prophet (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qcc7ojeeCDsYJaGhhwnnrxBRockTqqbB

## Hybrid Prediction
"""

!pip install prophet statsmodels xgboost scikit-learn -q

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from prophet import Prophet
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.ensemble import RandomForestRegressor, StackingRegressor
from sklearn.linear_model import Ridge
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

if not hasattr(np, "float_"):
    np.float_ = np.float64

plt.rcParams["figure.figsize"] = (14, 6)
plt.style.use('seaborn-v0_8-whitegrid')
print("âœ… KÃ¼tÃ¼phaneler yÃ¼klendi!")

df = pd.read_csv("cleaned_weather.csv")
df['date'] = pd.to_datetime(df['date'])

print(f"Toplam satÄ±r: {len(df):,}")
print(f"Tarih aralÄ±ÄŸÄ±: {df['date'].min()} - {df['date'].max()}")
print(f"Kolonlar: {df.columns.tolist()}")
df.head()

# Saatlik ortalama
df_hourly = df.set_index('date').resample('H').mean().reset_index()

# Temel zaman Ã¶zellikleri
df_hourly['hour'] = df_hourly['date'].dt.hour
df_hourly['day'] = df_hourly['date'].dt.day
df_hourly['month'] = df_hourly['date'].dt.month
df_hourly['dayofweek'] = df_hourly['date'].dt.dayofweek
df_hourly['dayofyear'] = df_hourly['date'].dt.dayofyear

# DÃ¶ngÃ¼sel Ã¶zellikler
df_hourly['hour_sin'] = np.sin(2 * np.pi * df_hourly['hour'] / 24)
df_hourly['hour_cos'] = np.cos(2 * np.pi * df_hourly['hour'] / 24)
df_hourly['month_sin'] = np.sin(2 * np.pi * df_hourly['month'] / 12)
df_hourly['month_cos'] = np.cos(2 * np.pi * df_hourly['month'] / 12)

# RÃ¼zgar yÃ¶nÃ¼ sin/cos
df_hourly['wd_sin'] = np.sin(np.deg2rad(df_hourly['wd']))
df_hourly['wd_cos'] = np.cos(np.deg2rad(df_hourly['wd']))

# â­ LAG FEATURES - Ã‡OK Ã–NEMLÄ°!
TARGET = 'T'
for lag in [1, 2, 3, 6, 12, 24]:
    df_hourly[f'T_lag_{lag}'] = df_hourly[TARGET].shift(lag)

# Rolling features
df_hourly['T_rolling_6h_mean'] = df_hourly[TARGET].rolling(window=6).mean()
df_hourly['T_rolling_24h_mean'] = df_hourly[TARGET].rolling(window=24).mean()
df_hourly['T_rolling_6h_std'] = df_hourly[TARGET].rolling(window=6).std()

# NaN'larÄ± temizle (lag ve rolling'den dolayÄ±)
df_hourly = df_hourly.dropna().reset_index(drop=True)

print(f"Saatlik veri (temizlik sonrasÄ±): {len(df_hourly):,} satÄ±r")
print(f"Tarih aralÄ±ÄŸÄ±: {df_hourly['date'].min()} - {df_hourly['date'].max()}")

TEST_DAYS = 7
TEST_SIZE = TEST_DAYS * 24

train = df_hourly[:-TEST_SIZE].copy()
test = df_hourly[-TEST_SIZE:].copy()

print("=" * 60)
print(f"Train: {len(train):,} satÄ±r ({train['date'].min().date()} - {train['date'].max().date()})")
print(f"Test: {len(test):,} satÄ±r ({test['date'].min().date()} - {test['date'].max().date()})")
print("=" * 60)

# GÃ¶rselleÅŸtirme
plt.figure(figsize=(14, 5))
plt.plot(train['date'], train[TARGET], label='Train', linewidth=0.7)
plt.plot(test['date'], test[TARGET], label='Test', linewidth=1.5, color='red')
plt.axvline(x=test['date'].iloc[0], color='black', linestyle='--')
plt.title('Train/Test Split', fontsize=14, fontweight='bold')
plt.legend()
plt.show()

def calculate_metrics(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # MAPE - sÄ±fÄ±ra yakÄ±n deÄŸerleri filtrele
    mask = np.abs(y_true) > 1.0  # Sadece |T| > 1Â°C olanlar
    if mask.sum() > 0:
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
    else:
        mape = np.nan

    return {
        'Model': model_name,
        'MAE': round(mae, 4),
        'RMSE': round(rmse, 4),
        'MSE': round(mse, 4),
        'RÂ²': round(r2, 4),
        'MAPE (%)': round(mape, 2) if not np.isnan(mape) else 'N/A'
    }

all_results = []
all_predictions = {}
test_dates = test['date'].values
y_test_actual = test[TARGET].values

print("âœ… HazÄ±rlÄ±klar tamamlandÄ±!")

print("=" * 60)
print("1. PROPHET MODELÄ°")
print("=" * 60)

# Prophet veri hazÄ±rlÄ±ÄŸÄ±
prophet_train = train[['date', TARGET]].rename(columns={'date': 'ds', TARGET: 'y'})

# Model
prophet_model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=True,
    seasonality_mode='additive',
    changepoint_prior_scale=0.05
)

prophet_model.fit(prophet_train)

# Future dataframe
future = pd.DataFrame({'ds': test['date']})
prophet_forecast = prophet_model.predict(future)
prophet_pred = prophet_forecast['yhat'].values

# Metrik
prophet_metrics = calculate_metrics(y_test_actual, prophet_pred, 'Prophet')
all_results.append(prophet_metrics)
all_predictions['Prophet'] = prophet_pred

print(f"\nðŸ“Š Prophet: MAE={prophet_metrics['MAE']}, RMSE={prophet_metrics['RMSE']}, RÂ²={prophet_metrics['RÂ²']}")

print("=" * 60)
print("2. SARIMA MODELÄ°")
print("=" * 60)

# Son 1000 saat ile eÄŸit (hÄ±z iÃ§in)
sarima_data = train[TARGET].iloc[-1000:].values

print("SARIMA eÄŸitiliyor...")
sarima_model = SARIMAX(
    sarima_data,
    order=(1, 1, 1),
    seasonal_order=(1, 0, 1, 24),
    enforce_stationarity=False,
    enforce_invertibility=False
)
sarima_result = sarima_model.fit(disp=False)

# Tahmin
sarima_pred = sarima_result.forecast(steps=len(test))

# Metrik
sarima_metrics = calculate_metrics(y_test_actual, sarima_pred, 'SARIMA')
all_results.append(sarima_metrics)
all_predictions['SARIMA'] = sarima_pred

print(f"\nðŸ“Š SARIMA: MAE={sarima_metrics['MAE']}, RMSE={sarima_metrics['RMSE']}, RÂ²={sarima_metrics['RÂ²']}")

print("=" * 60)
print("ML MODELLERÄ° Ä°Ã‡Ä°N FEATURE HAZIRLIÄžI")
print("=" * 60)

# âš ï¸ Leak feature'larÄ± Ã‡IKAR, Lag feature'larÄ± EKLE
FEATURES = [
    # Zaman Ã¶zellikleri
    'hour', 'day', 'month', 'dayofweek', 'dayofyear',
    'hour_sin', 'hour_cos', 'month_sin', 'month_cos',

    # Meteorolojik (leak olmayan)
    'p', 'rh', 'sh', 'rho', 'wv', 'wd_sin', 'wd_cos',
    'rain', 'SWDR', 'PAR',

    # â­ LAG FEATURES - Kritik!
    'T_lag_1', 'T_lag_2', 'T_lag_3', 'T_lag_6', 'T_lag_12', 'T_lag_24',
    'T_rolling_6h_mean', 'T_rolling_24h_mean', 'T_rolling_6h_std'
]

available_features = [f for f in FEATURES if f in train.columns]
print(f"Feature sayÄ±sÄ±: {len(available_features)}")

X_train = train[available_features].values
y_train = train[TARGET].values
X_test = test[available_features].values
y_test = test[TARGET].values

print(f"X_train: {X_train.shape}, X_test: {X_test.shape}")

print("=" * 60)
print("3. RANDOM FOREST MODELÄ°")
print("=" * 60)

rf_model = RandomForestRegressor(
    n_estimators=200,
    max_depth=15,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)

print("EÄŸitiliyor...")
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

rf_metrics = calculate_metrics(y_test, rf_pred, 'Random Forest')
all_results.append(rf_metrics)
all_predictions['Random Forest'] = rf_pred

print(f"\nðŸ“Š Random Forest: MAE={rf_metrics['MAE']}, RMSE={rf_metrics['RMSE']}, RÂ²={rf_metrics['RÂ²']}")

# Feature importance
feat_imp = pd.DataFrame({'Feature': available_features, 'Importance': rf_model.feature_importances_})
print("\nðŸ” Top 5 Features:")
print(feat_imp.sort_values('Importance', ascending=False).head().to_string(index=False))

print("=" * 60)
print("4. XGBOOST MODELÄ°")
print("=" * 60)

xgb_model = XGBRegressor(
    n_estimators=300,
    max_depth=8,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1,
    verbosity=0
)

print("EÄŸitiliyor...")
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)

xgb_metrics = calculate_metrics(y_test, xgb_pred, 'XGBoost')
all_results.append(xgb_metrics)
all_predictions['XGBoost'] = xgb_pred

print(f"\nðŸ“Š XGBoost: MAE={xgb_metrics['MAE']}, RMSE={xgb_metrics['RMSE']}, RÂ²={xgb_metrics['RÂ²']}")

print("=" * 60)
print("5. HÄ°BRÄ°T MODEL (Stacking)")
print("=" * 60)

hybrid_model = StackingRegressor(
    estimators=[
        ('rf', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),
        ('xgb', XGBRegressor(n_estimators=150, max_depth=6, learning_rate=0.05, random_state=42, verbosity=0))
    ],
    final_estimator=Ridge(alpha=1.0),
    cv=5,
    n_jobs=-1
)

print("EÄŸitiliyor...")
hybrid_model.fit(X_train, y_train)
hybrid_pred = hybrid_model.predict(X_test)

hybrid_metrics = calculate_metrics(y_test, hybrid_pred, 'Hybrid (Stacking)')
all_results.append(hybrid_metrics)
all_predictions['Hybrid'] = hybrid_pred

print(f"\nðŸ“Š Hybrid: MAE={hybrid_metrics['MAE']}, RMSE={hybrid_metrics['RMSE']}, RÂ²={hybrid_metrics['RÂ²']}")

print("=" * 70)
print("ðŸ“Š TÃœM MODELLER - KARÅžILAÅžTIRMA")
print("=" * 70)

results_df = pd.DataFrame(all_results)
results_df = results_df.drop_duplicates(subset=['Model'])
results_df = results_df.sort_values('RMSE').reset_index(drop=True)

print(results_df.to_string(index=False))

best = results_df.iloc[0]
print(f"\nðŸ† En Ä°yi Model: {best['Model']}")
print(f"   MAE: {best['MAE']} Â°C")
print(f"   RMSE: {best['RMSE']} Â°C")
print(f"   RÂ²: {best['RÂ²']}")

fig, axes = plt.subplots(2, 2, figsize=(16, 12), dpi=300)

# All predictions
ax1 = axes[0, 0]
ax1.plot(test_dates, y_test_actual, 'k-', label='Actual', linewidth=2)
colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']
for i, (name, pred) in enumerate(all_predictions.items()):
    ax1.plot(test_dates, pred, label=name, alpha=0.7, linewidth=1.5)
ax1.set_title('All Model Predictions', fontsize=12, fontweight='bold')
ax1.legend()
ax1.set_ylabel('Temperature (Â°C)')

# MAE comparison
ax2 = axes[0, 1]
ax2.barh(results_df['Model'], results_df['MAE'], color=colors[:len(results_df)])
ax2.set_title('MAE Comparison', fontsize=12, fontweight='bold')
ax2.set_xlabel('MAE (Â°C)')

# RÂ² comparison
ax3 = axes[1, 0]
ax3.barh(results_df['Model'], results_df['RÂ²'], color=colors[:len(results_df)])
ax3.set_title('RÂ² Comparison', fontsize=12, fontweight='bold')
ax3.set_xlabel('RÂ²')
ax3.axvline(x=0, color='red', linestyle='--')

# Best model detail
best_name = results_df.iloc[0]['Model']
best_pred = all_predictions.get(best_name, list(all_predictions.values())[0])
ax4 = axes[1, 1]
ax4.plot(test_dates, y_test_actual, 'b-', label='Actual', linewidth=2)
ax4.plot(test_dates, best_pred, 'r--', label=f'{best_name} Prediction', linewidth=2)
ax4.fill_between(test_dates, y_test_actual, best_pred, alpha=0.3, color='gray')
ax4.set_title(f'Best Model: {best_name}', fontsize=12, fontweight='bold')
ax4.legend()
ax4.set_ylabel('Temperature (Â°C)')

plt.tight_layout()
plt.show()

print("=" * 70)
print("ðŸ“‹ FÄ°NAL RAPOR")
print("=" * 70)

print(f"""
ðŸ“… Veri Bilgileri:
   Toplam: {len(df):,} satÄ±r (10 dakikalÄ±k)
   Saatlik: {len(df_hourly):,} satÄ±r
   Test: Son {TEST_DAYS} gÃ¼n ({TEST_SIZE} saat)

ðŸŽ¯ Hedef: SÄ±caklÄ±k (T) tahmini

ðŸ“Š Model PerformanslarÄ±:
""")
print(results_df.to_string(index=False))

print(f"""

ðŸ† En Ä°yi Model: {results_df.iloc[0]['Model']}

ðŸ’¡ DeÄŸerlendirme:
   â€¢ Lag features (geÃ§miÅŸ sÄ±caklÄ±k deÄŸerleri) en Ã¶nemli Ã¶zellikler
   â€¢ ML modelleri zaman serisi modellerinden daha iyi performans gÃ¶sterdi
   â€¢ Hibrit yaklaÅŸÄ±m modellerin gÃ¼Ã§lÃ¼ yÃ¶nlerini birleÅŸtiriyor
""")

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

best_models = ['Hybrid', 'Random Forest', 'XGBoost']
colors = ['#2ecc71', '#9b59b6', '#f39c12']

for idx, model in enumerate(best_models):
    pred = all_predictions[model]
    ax = axes[idx]

    ax.scatter(y_test_actual, pred, alpha=0.6, color=colors[idx], s=30)

    # MÃ¼kemmel tahmin Ã§izgisi
    min_val, max_val = min(y_test_actual.min(), pred.min()), max(y_test_actual.max(), pred.max())
    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='MÃ¼kemmel Tahmin')

    # RÂ² gÃ¶ster
    r2 = r2_score(y_test_actual, pred)
    ax.text(0.05, 0.95, f'RÂ² = {r2:.4f}', transform=ax.transAxes, fontsize=12,
            fontweight='bold', verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    ax.set_xlabel('GerÃ§ek SÄ±caklÄ±k (Â°C)', fontsize=11)
    ax.set_ylabel('Tahmin (Â°C)', fontsize=11)
    ax.set_title(model, fontsize=12, fontweight='bold')
    ax.legend()

plt.suptitle('GerÃ§ek vs Tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

best_models = ['Hybrid', 'Random Forest', 'XGBoost']
colors = ['#2ecc71', '#9b59b6', '#f39c12']

for idx, model in enumerate(best_models):
    pred = all_predictions[model]
    errors = y_test_actual - pred

    ax = axes[idx]
    ax.hist(errors, bins=25, color=colors[idx], edgecolor='black', alpha=0.7)
    ax.axvline(x=0, color='red', linestyle='--', linewidth=2)
    ax.axvline(x=np.mean(errors), color='blue', linestyle=':', linewidth=2,
               label=f'Ort: {np.mean(errors):.3f}Â°C')

    ax.set_xlabel('Tahmin HatasÄ± (Â°C)', fontsize=11)
    ax.set_ylabel('Frekans', fontsize=11)
    ax.set_title(f'{model} - Hata DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight='bold')
    ax.legend()

plt.tight_layout()
plt.show()

# Test setine tahminleri ekle
test_analysis = test[['date', 'hour', TARGET]].copy()
test_analysis['Hybrid_pred'] = all_predictions['Hybrid']
test_analysis['RF_pred'] = all_predictions['Random Forest']
test_analysis['XGB_pred'] = all_predictions['XGBoost']

# Saatlik MAE hesapla
hourly_mae = test_analysis.groupby('hour').apply(
    lambda x: pd.Series({
        'Hybrid': np.abs(x[TARGET] - x['Hybrid_pred']).mean(),
        'Random Forest': np.abs(x[TARGET] - x['RF_pred']).mean(),
        'XGBoost': np.abs(x[TARGET] - x['XGB_pred']).mean()
    })
)

# GÃ¶rselleÅŸtir
fig, ax = plt.subplots(figsize=(12, 5))
hourly_mae.plot(kind='bar', ax=ax, width=0.8, alpha=0.8)
ax.set_xlabel('Saat', fontsize=11)
ax.set_ylabel('MAE (Â°C)', fontsize=11)
ax.set_title('Saatlik Ortalama Mutlak Hata', fontsize=14, fontweight='bold')
ax.legend(title='Model')
ax.set_xticklabels(range(24), rotation=0)
plt.tight_layout()
plt.show()

print("\nðŸ“Š En yÃ¼ksek hata saatleri (Hybrid):")
print(hourly_mae['Hybrid'].sort_values(ascending=False).head())

# RF ve XGBoost feature importance
rf_imp = pd.DataFrame({'Feature': available_features, 'RF': rf_model.feature_importances_})
xgb_imp = pd.DataFrame({'Feature': available_features, 'XGBoost': xgb_model.feature_importances_})

importance_df = rf_imp.merge(xgb_imp, on='Feature')
importance_df['Average'] = (importance_df['RF'] + importance_df['XGBoost']) / 2
importance_df = importance_df.sort_values('Average', ascending=False)

# Top 15 feature
fig, ax = plt.subplots(figsize=(10, 8))
top_15 = importance_df.head(15)

x = np.arange(len(top_15))
width = 0.35

bars1 = ax.barh(x - width/2, top_15['RF'], width, label='Random Forest', color='#9b59b6', alpha=0.8)
bars2 = ax.barh(x + width/2, top_15['XGBoost'], width, label='XGBoost', color='#f39c12', alpha=0.8)

ax.set_yticks(x)
ax.set_yticklabels(top_15['Feature'])
ax.invert_yaxis()
ax.set_xlabel('Importance', fontsize=11)
ax.set_title('Top 15 Feature Importance', fontsize=14, fontweight='bold')
ax.legend()

plt.tight_layout()
plt.show()

print("\nðŸ” En Ã–nemli 5 Feature:")
print(importance_df[['Feature', 'Average']].head().to_string(index=False))

# Model karÅŸÄ±laÅŸtÄ±rma tablosu
results_df.to_csv('model_comparison_results.csv', index=False)

# Tahminler
predictions_df = pd.DataFrame({
    'date': test_dates,
    'actual': y_test_actual,
    **all_predictions
})
predictions_df.to_csv('all_model_predictions.csv', index=False)

# Feature importance
importance_df.to_csv('feature_importance.csv', index=False)

print("âœ… Dosyalar kaydedildi:")
print("   â€¢ model_comparison_results.csv")
print("   â€¢ all_model_predictions.csv")
print("   â€¢ feature_importance.csv")

print("=" * 70)
print("ðŸ“ AKADEMÄ°K Ã–ZET - HAVA DURUMU TAHMÄ°N MODELLERÄ°")
print("=" * 70)

print("""
AMAÃ‡:
Saatlik sÄ±caklÄ±k (T) tahmini iÃ§in farklÄ± makine Ã¶ÄŸrenmesi ve
zaman serisi modellerinin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi.

VERÄ° SETÄ°:
- Kaynak: 10 dakikalÄ±k meteorolojik Ã¶lÃ§Ã¼mler
- DÃ¶nem: 2020-01-01 - 2020-12-31
- Ã–rneklem: 52,696 gÃ¶zlem â†’ 8,736 saatlik ortalama
- Test periyodu: Son 7 gÃ¼n (168 saat)

MODELLER:
1. Prophet (Facebook) - Aditif mevsimsellik modeli
2. SARIMA (1,1,1)(1,0,1,24) - Klasik zaman serisi
3. Random Forest - Ensemble aÄŸaÃ§ modeli
4. XGBoost - Gradient boosting
5. Hybrid Stacking - RF + XGBoost + Ridge meta-learner

Ã–ZELLÄ°KLER:
- Zaman Ã¶zellikleri: saat, gÃ¼n, ay, dÃ¶ngÃ¼sel (sin/cos)
- Meteorolojik: basÄ±nÃ§, nem, rÃ¼zgar, radyasyon
- Lag features: T(t-1), T(t-6), T(t-24) vb.
- Rolling: 6h ve 24h hareketli ortalama/std

SONUÃ‡LAR:
""")

print(results_df[['Model', 'MAE', 'RMSE', 'RÂ²']].to_string(index=False))

print(f"""

BULGULAR:
- En iyi model: Hybrid Stacking (RÂ² = 0.949, MAE = 0.25Â°C)
- Lag features model performansÄ±nÄ± dramatik ÅŸekilde artÄ±rdÄ±
- ML modelleri klasik zaman serisi modellerinden Ã¼stÃ¼n
- Prophet ve SARIMA 7 gÃ¼nlÃ¼k horizonda yetersiz kaldÄ±

Ã–NERÄ°LER:
- KÄ±sa vadeli tahmin (1-24 saat): Hybrid veya RF
- Feature engineering kritik Ã¶neme sahip
- Ensemble yaklaÅŸÄ±mlar tek modellere gÃ¶re daha robust
""")
print("=" * 70)

# Ã–nce kurulum
!pip install catboost -q

from catboost import CatBoostRegressor

print("=" * 60)
print("5. CATBOOST MODELÄ°")
print("=" * 60)

catboost_model = CatBoostRegressor(
    iterations=500,
    depth=8,
    learning_rate=0.05,
    l2_leaf_reg=3,
    random_seed=42,
    verbose=False
)

print("CatBoost eÄŸitiliyor...")
catboost_model.fit(X_train, y_train)
catboost_pred = catboost_model.predict(X_test)

# Metrik
catboost_metrics = calculate_metrics(y_test, catboost_pred, 'CatBoost')
all_results.append(catboost_metrics)
all_predictions['CatBoost'] = catboost_pred

print(f"\nðŸ“Š CatBoost: MAE={catboost_metrics['MAE']}, RMSE={catboost_metrics['RMSE']}, RÂ²={catboost_metrics['RÂ²']}")

# Feature Importance
catboost_importance = pd.DataFrame({
    'Feature': available_features,
    'Importance': catboost_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nðŸ” Top 5 Features:")
print(catboost_importance.head().to_string(index=False))

from catboost import CatBoostRegressor

print("=" * 60)
print("6. HÄ°BRÄ°T MODEL (Stacking - RF + XGB + CatBoost)")
print("=" * 60)

hybrid_model = StackingRegressor(
    estimators=[
        ('rf', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),
        ('xgb', XGBRegressor(n_estimators=150, max_depth=6, learning_rate=0.05, random_state=42, verbosity=0)),
        ('catboost', CatBoostRegressor(iterations=200, depth=6, learning_rate=0.05, random_seed=42, verbose=False))
    ],
    final_estimator=Ridge(alpha=1.0),
    cv=5,
    n_jobs=-1
)

print("Hibrit model eÄŸitiliyor...")
hybrid_model.fit(X_train, y_train)
hybrid_pred = hybrid_model.predict(X_test)

# Eski Hybrid sonucunu gÃ¼ncelle
all_results = [r for r in all_results if r['Model'] != 'Hybrid (Stacking)']
all_predictions.pop('Hybrid', None)

hybrid_metrics = calculate_metrics(y_test, hybrid_pred, 'Hybrid (RF+XGB+Cat)')
all_results.append(hybrid_metrics)
all_predictions['Hybrid'] = hybrid_pred

print(f"\nðŸ“Š Hybrid: MAE={hybrid_metrics['MAE']}, RMSE={hybrid_metrics['RMSE']}, RÂ²={hybrid_metrics['RÂ²']}")

print("=" * 70)
print("ðŸ“Š TÃœM MODELLER - KARÅžILAÅžTIRMA (CatBoost Dahil)")
print("=" * 70)

results_df = pd.DataFrame(all_results)
results_df = results_df.drop_duplicates(subset=['Model'])
results_df = results_df.sort_values('RMSE').reset_index(drop=True)

print(results_df.to_string(index=False))

best = results_df.iloc[0]
print(f"\nðŸ† En Ä°yi Model: {best['Model']}")
print(f"   MAE: {best['MAE']} Â°C")
print(f"   RMSE: {best['RMSE']} Â°C")
print(f"   RÂ²: {best['RÂ²']}")

fig, axes = plt.subplots(2, 2, figsize=(16, 12), dpi=600)

# 1. All ML model predictions
ax1 = axes[0, 0]
ax1.plot(test_dates, y_test_actual, 'k-', label='Actual', linewidth=2.5)
ml_models = ['Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']
colors = ['#9b59b6', '#f39c12', '#1abc9c', '#e74c3c']
for model, color in zip(ml_models, colors):
    if model in all_predictions:
        ax1.plot(test_dates, all_predictions[model], label=model, alpha=0.7, linewidth=1.5, color=color)
ax1.set_title('ML Model Predictions', fontsize=12, fontweight='bold')
ax1.set_ylabel('Temperature (Â°C)')
ax1.legend()

# 2. RMSE Comparison
ax2 = axes[0, 1]
ml_results = results_df[~results_df['Model'].isin(['Prophet', 'SARIMA'])]
colors_bar = ['#2ecc71', '#9b59b6', '#f39c12', '#1abc9c', '#e74c3c']
ax2.barh(ml_results['Model'], ml_results['RMSE'], color=colors_bar[:len(ml_results)])
ax2.set_title('RMSE Comparison (ML Models)', fontsize=12, fontweight='bold')
ax2.set_xlabel('RMSE (Â°C)')
for i, v in enumerate(ml_results['RMSE']):
    ax2.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)

# 3. RÂ² Comparison
ax3 = axes[1, 0]
ax3.barh(ml_results['Model'], ml_results['RÂ²'], color=colors_bar[:len(ml_results)])
ax3.set_title('RÂ² Comparison (ML Models)', fontsize=12, fontweight='bold')
ax3.set_xlabel('RÂ²')
for i, v in enumerate(ml_results['RÂ²']):
    ax3.text(v + 0.005, i, f'{v:.4f}', va='center', fontsize=10)

# 4. MAE Comparison
ax4 = axes[1, 1]
ax4.barh(ml_results['Model'], ml_results['MAE'], color=colors_bar[:len(ml_results)])
ax4.set_title('MAE Comparison (ML Models)', fontsize=12, fontweight='bold')
ax4.set_xlabel('MAE (Â°C)')
for i, v in enumerate(ml_results['MAE']):
    ax4.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(12, 10), dpi=600)
axes = axes.flatten()

models = ['Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']
colors = ['#9b59b6', '#f39c12', '#1abc9c', '#e74c3c']

for idx, (model, color) in enumerate(zip(models, colors)):
    if model in all_predictions:
        pred = all_predictions[model]
        ax = axes[idx]

        ax.scatter(y_test_actual, pred, alpha=0.6, color=color, s=30)

        min_val = min(y_test_actual.min(), pred.min())
        max_val = max(y_test_actual.max(), pred.max())
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)

        r2 = r2_score(y_test_actual, pred)
        mae = mean_absolute_error(y_test_actual, pred)
        ax.text(0.05, 0.95, f'RÂ² = {r2:.4f}\nMAE = {mae:.4f}Â°C',
                transform=ax.transAxes, fontsize=11, fontweight='bold',
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        ax.set_xlabel('Actual (Â°C)')
        ax.set_ylabel('Predicted (Â°C)')
        ax.set_title(model, fontsize=12, fontweight='bold')

plt.suptitle('Actual vs Predicted - ML Models', fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.show()

# All models' feature importance
importance_combined = pd.DataFrame({'Feature': available_features})
importance_combined['RF'] = rf_model.feature_importances_
importance_combined['XGBoost'] = xgb_model.feature_importances_
importance_combined['CatBoost'] = catboost_model.feature_importances_
importance_combined['Average'] = importance_combined[['RF', 'XGBoost', 'CatBoost']].mean(axis=1)
importance_combined = importance_combined.sort_values('Average', ascending=False)

# Visualization
fig, ax = plt.subplots(figsize=(12, 10), dpi=600)
top_15 = importance_combined.head(15)

x = np.arange(len(top_15))
width = 0.25

ax.barh(x - width, top_15['RF'], width, label='Random Forest', color='#9b59b6', alpha=0.8)
ax.barh(x, top_15['XGBoost'], width, label='XGBoost', color='#f39c12', alpha=0.8)
ax.barh(x + width, top_15['CatBoost'], width, label='CatBoost', color='#1abc9c', alpha=0.8)

ax.set_yticks(x)
ax.set_yticklabels(top_15['Feature'])
ax.invert_yaxis()
ax.set_xlabel('Importance', fontsize=11)
ax.set_title('Feature Importance Comparison (Top 15)', fontsize=14, fontweight='bold')
ax.legend()

plt.tight_layout()
plt.show()

print("\nðŸ” Top 10 Most Important Features (Average):")
print(importance_combined[['Feature', 'Average']].head(10).to_string(index=False))

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import seaborn as sns
from scipy import stats
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pandas as pd
import numpy as np

# Akademik stil ayarlarÄ±
plt.rcParams.update({
    'font.size': 11,
    'font.family': 'serif',
    'axes.labelsize': 12,
    'axes.titlesize': 13,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'legend.fontsize': 10,
    'figure.titlesize': 14,
    'figure.dpi': 150,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'axes.grid': True,
    'grid.alpha': 0.3
})

# Renk paleti (akademik ve tutarlÄ±)
COLORS = {
    'Prophet': '#E74C3C',
    'SARIMA': '#3498DB',
    'Random Forest': '#9B59B6',
    'XGBoost': '#F39C12',
    'CatBoost': '#1ABC9C',
    'Hybrid': '#2C3E50',
    'Actual': '#000000'
}

print("âœ… Akademik gÃ¶rselleÅŸtirme ayarlarÄ± yÃ¼klendi!")

print("=" * 70)
print("TABLO 1: VERÄ° SETÄ° TANIMLAYICI Ä°STATÄ°STÄ°KLERÄ°")
print("=" * 70)

# Ana meteorolojik deÄŸiÅŸkenler
main_vars = ['T', 'p', 'rh', 'wv', 'rain', 'SWDR', 'PAR']
available_vars = [v for v in main_vars if v in df_hourly.columns]

# Ä°statistikler
stats_df = df_hourly[available_vars].describe().T
stats_df['DeÄŸiÅŸken'] = stats_df.index
stats_df = stats_df[['DeÄŸiÅŸken', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]
stats_df.columns = ['DeÄŸiÅŸken', 'N', 'Ortalama', 'Std. Sapma', 'Min', 'Q1', 'Medyan', 'Q3', 'Max']

# Yuvarlama
for col in ['Ortalama', 'Std. Sapma', 'Min', 'Q1', 'Medyan', 'Q3', 'Max']:
    stats_df[col] = stats_df[col].round(2)
stats_df['N'] = stats_df['N'].astype(int)

# DeÄŸiÅŸken aÃ§Ä±klamalarÄ±
var_descriptions = {
    'T': 'SÄ±caklÄ±k (Â°C)',
    'p': 'BasÄ±nÃ§ (hPa)',
    'rh': 'BaÄŸÄ±l Nem (%)',
    'wv': 'RÃ¼zgar HÄ±zÄ± (m/s)',
    'rain': 'YaÄŸÄ±ÅŸ (mm)',
    'SWDR': 'KÄ±sa Dalga Radyasyon (W/mÂ²)',
    'PAR': 'FAR (Î¼mol/mÂ²s)'
}
stats_df['AÃ§Ä±klama'] = stats_df['DeÄŸiÅŸken'].map(var_descriptions)

print(stats_df.to_string(index=False))

# LaTeX formatÄ±nda kaydet
latex_table1 = stats_df.to_latex(index=False, caption='Veri Seti TanÄ±mlayÄ±cÄ± Ä°statistikleri',
                                  label='tab:descriptive_stats')
with open('table1_descriptive_stats.tex', 'w') as f:
    f.write(latex_table1)
print("\nâœ… table1_descriptive_stats.tex kaydedildi")

print("=" * 70)
print("TABLO 2: EÄžÄ°TÄ°M VE TEST SETÄ° BÄ°LGÄ°LERÄ°")
print("=" * 70)

dataset_info = pd.DataFrame({
    'Ã–zellik': [
        'Toplam GÃ¶zlem (Ham)',
        'Toplam GÃ¶zlem (Saatlik)',
        'EÄŸitim Seti GÃ¶zlem',
        'Test Seti GÃ¶zlem',
        'EÄŸitim BaÅŸlangÄ±Ã§',
        'EÄŸitim BitiÅŸ',
        'Test BaÅŸlangÄ±Ã§',
        'Test BitiÅŸ',
        'Ã–zellik SayÄ±sÄ±',
        'Test Periyodu'
    ],
    'DeÄŸer': [
        f"{len(df):,}",
        f"{len(df_hourly):,}",
        f"{len(train):,}",
        f"{len(test):,}",
        train['date'].min().strftime('%Y-%m-%d %H:%M'),
        train['date'].max().strftime('%Y-%m-%d %H:%M'),
        test['date'].min().strftime('%Y-%m-%d %H:%M'),
        test['date'].max().strftime('%Y-%m-%d %H:%M'),
        len(available_features),
        f"{TEST_DAYS} gÃ¼n ({TEST_SIZE} saat)"
    ]
})

print(dataset_info.to_string(index=False))

dataset_info.to_csv('table2_dataset_info.csv', index=False)
print("\nâœ… table2_dataset_info.csv kaydedildi")

print("=" * 70)
print("TABLO 3: MODEL PERFORMANS KARÅžILAÅžTIRMASI")
print("=" * 70)

# DetaylÄ± metrikler hesapla
def detailed_metrics(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    # MAPE (|T| > 1 iÃ§in)
    mask = np.abs(y_true) > 1.0
    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.nan

    # Max Error
    max_error = np.max(np.abs(y_true - y_pred))

    # Correlation
    corr = np.corrcoef(y_true, y_pred)[0, 1]

    return {
        'Model': model_name,
        'MAE (Â°C)': round(mae, 4),
        'RMSE (Â°C)': round(rmse, 4),
        'MSE': round(mse, 4),
        'RÂ²': round(r2, 4),
        'MAPE (%)': round(mape, 2) if not np.isnan(mape) else '-',
        'Max Error (Â°C)': round(max_error, 2),
        'Pearson r': round(corr, 4)
    }

# TÃ¼m modeller iÃ§in hesapla
performance_results = []
for model_name, pred in all_predictions.items():
    metrics = detailed_metrics(y_test_actual, pred, model_name)
    performance_results.append(metrics)

performance_df = pd.DataFrame(performance_results)
performance_df = performance_df.sort_values('RMSE (Â°C)').reset_index(drop=True)

# SÄ±ralama ekle
performance_df.insert(0, 'SÄ±ra', range(1, len(performance_df) + 1))

print(performance_df.to_string(index=False))

# Kaydet
performance_df.to_csv('table3_model_performance.csv', index=False)
latex_table3 = performance_df.to_latex(index=False, caption='Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±',
                                        label='tab:model_performance')
with open('table3_model_performance.tex', 'w') as f:
    f.write(latex_table3)
print("\nâœ… table3_model_performance.csv ve .tex kaydedildi")

print("=" * 70)
print("TABLO 4: Ã–ZELLÄ°K Ã–NEMLÄ°LÄ°K SIRALAMASI (TOP 15)")
print("=" * 70)

# TÃ¼m modellerin importance deÄŸerlerini birleÅŸtir
importance_table = pd.DataFrame({'Ã–zellik': available_features})
importance_table['Random Forest'] = rf_model.feature_importances_
importance_table['XGBoost'] = xgb_model.feature_importances_
importance_table['CatBoost'] = catboost_model.feature_importances_

# Normalize et (0-100 arasÄ±)
for col in ['Random Forest', 'XGBoost', 'CatBoost']:
    importance_table[col] = (importance_table[col] / importance_table[col].sum() * 100).round(2)

importance_table['Ortalama'] = importance_table[['Random Forest', 'XGBoost', 'CatBoost']].mean(axis=1).round(2)
importance_table = importance_table.sort_values('Ortalama', ascending=False).reset_index(drop=True)

# SÄ±ra ekle
importance_table.insert(0, 'SÄ±ra', range(1, len(importance_table) + 1))

# Ã–zellik aÃ§Ä±klamalarÄ±
feature_desc = {
    'T_lag_1': 't-1 SÄ±caklÄ±k',
    'T_lag_2': 't-2 SÄ±caklÄ±k',
    'T_lag_3': 't-3 SÄ±caklÄ±k',
    'T_lag_6': 't-6 SÄ±caklÄ±k',
    'T_lag_12': 't-12 SÄ±caklÄ±k',
    'T_lag_24': 't-24 SÄ±caklÄ±k',
    'T_rolling_6h_mean': '6 Saat Ort.',
    'T_rolling_24h_mean': '24 Saat Ort.',
    'T_rolling_6h_std': '6 Saat Std.',
    'hour': 'Saat',
    'hour_sin': 'Saat (sin)',
    'hour_cos': 'Saat (cos)',
    'month': 'Ay',
    'month_sin': 'Ay (sin)',
    'month_cos': 'Ay (cos)',
    'p': 'BasÄ±nÃ§',
    'rh': 'Nem',
    'wv': 'RÃ¼zgar HÄ±zÄ±',
    'SWDR': 'Radyasyon',
    'PAR': 'FAR'
}
importance_table['AÃ§Ä±klama'] = importance_table['Ã–zellik'].map(feature_desc).fillna(importance_table['Ã–zellik'])

print(importance_table.head(15).to_string(index=False))

importance_table.head(15).to_csv('table4_feature_importance.csv', index=False)
print("\nâœ… table4_feature_importance.csv kaydedildi")

fig, axes = plt.subplots(3, 1, figsize=(14, 10), dpi=600)

# 1. All data
ax1 = axes[0]
ax1.plot(df_hourly['date'], df_hourly[TARGET], linewidth=0.5, color='#2C3E50', alpha=0.8)
ax1.axvline(x=test['date'].iloc[0], color='red', linestyle='--', linewidth=1.5, label='Train/Test Split')
ax1.set_title('(a) Temperature Time Series - Complete Dataset', fontweight='bold')
ax1.set_ylabel('Temperature (Â°C)')
ax1.legend(loc='upper right')

# 2. Monthly average and std
monthly = df_hourly.set_index('date').resample('M')[TARGET].agg(['mean', 'std']).reset_index()
ax2 = axes[1]
ax2.plot(monthly['date'], monthly['mean'], 'o-', color='#E74C3C', linewidth=2, markersize=6, label='Monthly Average')
ax2.fill_between(monthly['date'],
                  monthly['mean'] - monthly['std'],
                  monthly['mean'] + monthly['std'],
                  alpha=0.3, color='#E74C3C', label='Â±1 Std. Deviation')
ax2.set_title('(b) Monthly Temperature Trend', fontweight='bold')
ax2.set_ylabel('Temperature (Â°C)')
ax2.legend(loc='upper right')

# 3. Test period detail
ax3 = axes[2]
ax3.plot(test['date'], test[TARGET], linewidth=2, color='#2C3E50', label='Test Data')
ax3.set_title(f'(c) Test Period ({TEST_DAYS} Days)', fontweight='bold')
ax3.set_xlabel('Date')
ax3.set_ylabel('Temperature (Â°C)')
ax3.legend(loc='upper right')

plt.tight_layout()
plt.savefig('figure1_time_series_overview.png', dpi=300, bbox_inches='tight')
plt.savefig('figure1_time_series_overview.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure1_time_series_overview.png/pdf saved")

fig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=600)

# 1. Hourly pattern
ax1 = axes[0, 0]
hourly_stats = df_hourly.groupby('hour')[TARGET].agg(['mean', 'std'])
ax1.plot(hourly_stats.index, hourly_stats['mean'], 'o-', color='#3498DB', linewidth=2, markersize=8)
ax1.fill_between(hourly_stats.index,
                  hourly_stats['mean'] - hourly_stats['std'],
                  hourly_stats['mean'] + hourly_stats['std'],
                  alpha=0.3, color='#3498DB')
ax1.set_title('(a) Daily Temperature Cycle', fontweight='bold')
ax1.set_xlabel('Hour')
ax1.set_ylabel('Temperature (Â°C)')
ax1.set_xticks(range(0, 24, 2))

# 2. Monthly pattern
ax2 = axes[0, 1]
monthly_stats = df_hourly.groupby('month')[TARGET].agg(['mean', 'std'])
bars = ax2.bar(monthly_stats.index, monthly_stats['mean'], yerr=monthly_stats['std'],
               color='#E74C3C', alpha=0.7, capsize=3)
ax2.set_title('(b) Monthly Temperature Distribution', fontweight='bold')
ax2.set_xlabel('Month')
ax2.set_ylabel('Temperature (Â°C)')
ax2.set_xticks(range(1, 13))

# 3. Weekly pattern
ax3 = axes[1, 0]
daily_stats = df_hourly.groupby('dayofweek')[TARGET].agg(['mean', 'std'])
days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
ax3.bar(range(7), daily_stats['mean'], yerr=daily_stats['std'],
        color='#2ECC71', alpha=0.7, capsize=3)
ax3.set_title('(c) Weekly Temperature Distribution', fontweight='bold')
ax3.set_xlabel('Day')
ax3.set_ylabel('Temperature (Â°C)')
ax3.set_xticks(range(7))
ax3.set_xticklabels(days)

# 4. Temperature distribution (histogram)
ax4 = axes[1, 1]
ax4.hist(df_hourly[TARGET], bins=50, color='#9B59B6', alpha=0.7, edgecolor='black', linewidth=0.5)
ax4.axvline(df_hourly[TARGET].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df_hourly[TARGET].mean():.1f}Â°C')
ax4.axvline(df_hourly[TARGET].median(), color='blue', linestyle=':', linewidth=2, label=f'Median: {df_hourly[TARGET].median():.1f}Â°C')
ax4.set_title('(d) Temperature Distribution', fontweight='bold')
ax4.set_xlabel('Temperature (Â°C)')
ax4.set_ylabel('Frequency')
ax4.legend()

plt.tight_layout()
plt.savefig('figure2_seasonality_analysis.png', dpi=300, bbox_inches='tight')
plt.savefig('figure2_seasonality_analysis.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure2_seasonality_analysis.png/pdf saved")

# Korelasyon iÃ§in deÄŸiÅŸkenler
corr_vars = ['T', 'p', 'rh', 'wv', 'SWDR', 'PAR', 'rain',
             'T_lag_1', 'T_lag_6', 'T_lag_24', 'T_rolling_24h_mean']
corr_vars = [v for v in corr_vars if v in df_hourly.columns]

corr_matrix = df_hourly[corr_vars].corr()

# Variable labels
labels = {
    'T': 'Temperature',
    'p': 'Pressure',
    'rh': 'Humidity',
    'wv': 'Wind',
    'SWDR': 'Radiation',
    'PAR': 'PAR',
    'rain': 'Rain',
    'T_lag_1': 'T(t-1)',
    'T_lag_6': 'T(t-6)',
    'T_lag_24': 'T(t-24)',
    'T_rolling_24h_mean': 'T(24h Avg.)'
}

fig, ax = plt.subplots(figsize=(12, 10), dpi=600)
mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)

sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',
            center=0, vmin=-1, vmax=1, square=True, linewidths=0.5,
            xticklabels=[labels.get(v, v) for v in corr_vars],
            yticklabels=[labels.get(v, v) for v in corr_vars],
            cbar_kws={'label': 'Pearson Correlation Coefficient'}, ax=ax)

ax.set_title('Correlation Matrix Between Variables', fontweight='bold', fontsize=14)
plt.tight_layout()
plt.savefig('figure3_correlation_matrix.png', dpi=300, bbox_inches='tight')
plt.savefig('figure3_correlation_matrix.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure3_correlation_matrix.png/pdf saved")

fig, axes = plt.subplots(2, 1, figsize=(14, 10), dpi=600)

# 1. All models
ax1 = axes[0]
ax1.plot(test_dates, y_test_actual, color='black', linewidth=2.5, label='Actual', zorder=10)

for model_name in ['Prophet', 'SARIMA', 'Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']:
    if model_name in all_predictions:
        ax1.plot(test_dates, all_predictions[model_name],
                 color=COLORS.get(model_name, 'gray'),
                 linewidth=1.5, alpha=0.7, label=model_name)

ax1.set_title('(a) All Model Predictions', fontweight='bold')
ax1.set_ylabel('Temperature (Â°C)')
ax1.legend(loc='upper right', ncol=4)
ax1.grid(True, alpha=0.3)

# 2. Only best ML models
ax2 = axes[1]
ax2.plot(test_dates, y_test_actual, color='black', linewidth=2.5, label='Actual', zorder=10)

best_models = ['Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']
for model_name in best_models:
    if model_name in all_predictions:
        ax2.plot(test_dates, all_predictions[model_name],
                 color=COLORS.get(model_name, 'gray'),
                 linewidth=1.8, alpha=0.8, label=model_name)

ax2.set_title('(b) ML Model Predictions (Detailed)', fontweight='bold')
ax2.set_xlabel('Date')
ax2.set_ylabel('Temperature (Â°C)')
ax2.legend(loc='upper right')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('figure4_model_predictions.png', dpi=300, bbox_inches='tight')
plt.savefig('figure4_model_predictions.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure4_model_predictions.png/pdf saved")

fig, axes = plt.subplots(2, 3, figsize=(15, 10), dpi=600)
axes = axes.flatten()

models_to_plot = ['Prophet', 'SARIMA', 'Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']

for idx, model_name in enumerate(models_to_plot):
    ax = axes[idx]

    if model_name in all_predictions:
        pred = all_predictions[model_name]

        # Scatter plot
        ax.scatter(y_test_actual, pred, alpha=0.6, color=COLORS.get(model_name, 'gray'), s=25, edgecolors='white', linewidth=0.5)

        # Perfect prediction line
        min_val = min(y_test_actual.min(), pred.min())
        max_val = max(y_test_actual.max(), pred.max())
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')

        # Regression line
        slope, intercept, r_value, p_value, std_err = stats.linregress(y_test_actual, pred)
        line_x = np.array([min_val, max_val])
        line_y = slope * line_x + intercept
        ax.plot(line_x, line_y, 'b-', linewidth=1.5, alpha=0.7, label=f'Regression (r={r_value:.3f})')

        # Metrics
        r2 = r2_score(y_test_actual, pred)
        mae = mean_absolute_error(y_test_actual, pred)

        textstr = f'RÂ² = {r2:.4f}\nMAE = {mae:.3f}Â°C'
        props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,
                verticalalignment='top', bbox=props, fontweight='bold')

        ax.set_xlabel('Actual Temperature (Â°C)')
        ax.set_ylabel('Predicted Temperature (Â°C)')
        ax.set_title(f'({chr(97+idx)}) {model_name}', fontweight='bold')
        ax.legend(loc='lower right', fontsize=8)
        ax.set_aspect('equal', adjustable='box')

plt.tight_layout()
plt.savefig('figure5_scatter_plots.png', dpi=300, bbox_inches='tight')
plt.savefig('figure5_scatter_plots.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure5_scatter_plots.png/pdf saved")

fig, axes = plt.subplots(2, 3, figsize=(15, 10), dpi=300)
axes = axes.flatten()

models_to_plot = ['Prophet', 'SARIMA', 'Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']

for idx, model_name in enumerate(models_to_plot):
    ax = axes[idx]

    if model_name in all_predictions:
        pred = all_predictions[model_name]
        errors = y_test_actual - pred

        # Histogram
        n, bins, patches = ax.hist(errors, bins=30, color=COLORS.get(model_name, 'gray'),
                                    alpha=0.7, edgecolor='black', linewidth=0.5, density=True)

        # Normal distribution fit
        mu, std = stats.norm.fit(errors)
        x = np.linspace(errors.min(), errors.max(), 100)
        pdf = stats.norm.pdf(x, mu, std)
        ax.plot(x, pdf, 'r-', linewidth=2, label=f'Normal Fit\n(Î¼={mu:.2f}, Ïƒ={std:.2f})')

        # Zero line
        ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5)
        ax.axvline(x=mu, color='blue', linestyle=':', linewidth=1.5, label=f'Mean: {mu:.3f}')

        # Shapiro-Wilk test (normality)
        if len(errors) <= 5000:
            shapiro_stat, shapiro_p = stats.shapiro(errors[:5000])
            normal_text = f'Shapiro p={shapiro_p:.4f}'
        else:
            normal_text = ''

        ax.set_xlabel('Prediction Error (Â°C)')
        ax.set_ylabel('Density')
        ax.set_title(f'({chr(97+idx)}) {model_name}', fontweight='bold')
        ax.legend(loc='upper right', fontsize=8)

plt.tight_layout()
plt.savefig('figure6_error_distributions.png', dpi=600, bbox_inches='tight')
plt.savefig('figure6_error_distributions.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure6_error_distributions.png/pdf saved")

fig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=600)

# Only sorted data
plot_df = performance_df.sort_values('RMSE (Â°C)')

# 1. MAE
ax1 = axes[0, 0]
colors_list = [COLORS.get(m, 'gray') for m in plot_df['Model']]
bars1 = ax1.barh(plot_df['Model'], plot_df['MAE (Â°C)'], color=colors_list, alpha=0.8, edgecolor='black')
ax1.set_xlabel('MAE (Â°C)')
ax1.set_title('(a) Mean Absolute Error (MAE)', fontweight='bold')
for i, (v, m) in enumerate(zip(plot_df['MAE (Â°C)'], plot_df['Model'])):
    ax1.text(v + 0.1, i, f'{v:.3f}', va='center', fontsize=10, fontweight='bold')

# 2. RMSE
ax2 = axes[0, 1]
bars2 = ax2.barh(plot_df['Model'], plot_df['RMSE (Â°C)'], color=colors_list, alpha=0.8, edgecolor='black')
ax2.set_xlabel('RMSE (Â°C)')
ax2.set_title('(b) Root Mean Square Error (RMSE)', fontweight='bold')
for i, v in enumerate(plot_df['RMSE (Â°C)']):
    ax2.text(v + 0.1, i, f'{v:.3f}', va='center', fontsize=10, fontweight='bold')

# 3. RÂ²
ax3 = axes[1, 0]
r2_values = plot_df['RÂ²'].values
bars3 = ax3.barh(plot_df['Model'], r2_values, color=colors_list, alpha=0.8, edgecolor='black')
ax3.set_xlabel('RÂ²')
ax3.set_title('(c) Coefficient of Determination (RÂ²)', fontweight='bold')
ax3.axvline(x=0, color='red', linestyle='--', linewidth=1)
for i, v in enumerate(r2_values):
    ax3.text(max(v, 0) + 0.02, i, f'{v:.4f}', va='center', fontsize=10, fontweight='bold')

# 4. Pearson r
ax4 = axes[1, 1]
pearson_values = plot_df['Pearson r'].values
bars4 = ax4.barh(plot_df['Model'], pearson_values, color=colors_list, alpha=0.8, edgecolor='black')
ax4.set_xlabel('Pearson r')
ax4.set_title('(d) Pearson Correlation Coefficient', fontweight='bold')
for i, v in enumerate(pearson_values):
    ax4.text(max(v, 0) + 0.02, i, f'{v:.4f}', va='center', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.savefig('figure7_performance_comparison.png', dpi=300, bbox_inches='tight')
plt.savefig('figure7_performance_comparison.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure7_performance_comparison.png/pdf saved")

fig, axes = plt.subplots(1, 2, figsize=(14, 8), dpi=600)

# Top 15 features
top_n = 15
top_features = importance_table.head(top_n)

# 1. Grouped bar chart
ax1 = axes[0]
x = np.arange(top_n)
width = 0.25

bars1 = ax1.barh(x - width, top_features['Random Forest'], width, label='Random Forest',
                  color=COLORS['Random Forest'], alpha=0.8)
bars2 = ax1.barh(x, top_features['XGBoost'], width, label='XGBoost',
                  color=COLORS['XGBoost'], alpha=0.8)
bars3 = ax1.barh(x + width, top_features['CatBoost'], width, label='CatBoost',
                  color=COLORS['CatBoost'], alpha=0.8)

ax1.set_yticks(x)
ax1.set_yticklabels(top_features['Ã–zellik'])
ax1.invert_yaxis()
ax1.set_xlabel('Importance Score (%)')
ax1.set_title('(a) Model-Based Feature Importance', fontweight='bold')
ax1.legend(loc='lower right')

# 2. Average importance
ax2 = axes[1]
colors_feat = ['#E74C3C' if 'T_lag' in f or 'T_rolling' in f else '#3498DB' for f in top_features['Ã–zellik']]
bars = ax2.barh(top_features['Ã–zellik'], top_features['Ortalama'], color=colors_feat, alpha=0.8, edgecolor='black')
ax2.invert_yaxis()
ax2.set_xlabel('Average Importance Score (%)')
ax2.set_title('(b) Average Feature Importance', fontweight='bold')

# Add values
for i, v in enumerate(top_features['Ortalama']):
    ax2.text(v + 0.3, i, f'{v:.1f}%', va='center', fontsize=9)

# Legend for colors
from matplotlib.patches import Patch
legend_elements = [Patch(facecolor='#E74C3C', label='Lag/Rolling Features'),
                   Patch(facecolor='#3498DB', label='Other Features')]
ax2.legend(handles=legend_elements, loc='lower right')

plt.tight_layout()
plt.savefig('figure8_feature_importance.png', dpi=300, bbox_inches='tight')
plt.savefig('figure8_feature_importance.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure8_feature_importance.png/pdf saved")

# Error analysis with test data
test_with_errors = pd.DataFrame({
    'date': test_dates,
    'hour': test['hour'].values,
    'actual': y_test_actual
})

for model_name, pred in all_predictions.items():
    test_with_errors[f'{model_name}_error'] = y_test_actual - pred
    test_with_errors[f'{model_name}_abs_error'] = np.abs(y_test_actual - pred)

fig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=300)

# 1. Hourly MAE - ML models
ax1 = axes[0, 0]
ml_models = ['Random Forest', 'XGBoost', 'CatBoost', 'Hybrid']
for model in ml_models:
    hourly_mae = test_with_errors.groupby('hour')[f'{model}_abs_error'].mean()
    ax1.plot(hourly_mae.index, hourly_mae.values, 'o-', label=model,
             color=COLORS.get(model, 'gray'), linewidth=2, markersize=6)

ax1.set_xlabel('Hour')
ax1.set_ylabel('MAE (Â°C)')
ax1.set_title('(a) Hourly Mean Absolute Error', fontweight='bold')
ax1.set_xticks(range(0, 24, 2))
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. Box plot - hourly errors (Hybrid)
ax2 = axes[0, 1]
hourly_errors_hybrid = [test_with_errors[test_with_errors['hour'] == h]['Hybrid_error'].values
                        for h in range(24)]
bp = ax2.boxplot(hourly_errors_hybrid, positions=range(24), widths=0.6, patch_artist=True)
for patch in bp['boxes']:
    patch.set_facecolor(COLORS['Hybrid'])
    patch.set_alpha(0.6)
ax2.axhline(y=0, color='red', linestyle='--', linewidth=1)
ax2.set_xlabel('Hour')
ax2.set_ylabel('Prediction Error (Â°C)')
ax2.set_title('(b) Hourly Error Distribution (Hybrid Model)', fontweight='bold')
ax2.set_xticks(range(0, 24, 2))

# 3. Error time series
ax3 = axes[1, 0]
for model in ['Random Forest', 'Hybrid']:
    ax3.plot(test_dates, test_with_errors[f'{model}_error'],
             label=model, color=COLORS.get(model, 'gray'), alpha=0.7, linewidth=1)
ax3.axhline(y=0, color='red', linestyle='--', linewidth=1.5)
ax3.set_xlabel('Date')
ax3.set_ylabel('Prediction Error (Â°C)')
ax3.set_title('(c) Error Time Series', fontweight='bold')
ax3.legend()

# 4. Cumulative error
ax4 = axes[1, 1]
for model in ml_models:
    cumulative_mae = test_with_errors[f'{model}_abs_error'].expanding().mean()
    ax4.plot(test_dates, cumulative_mae, label=model,
             color=COLORS.get(model, 'gray'), linewidth=2)

ax4.set_xlabel('Date')
ax4.set_ylabel('Cumulative MAE (Â°C)')
ax4.set_title('(d) Cumulative Mean Absolute Error', fontweight='bold')
ax4.legend()

plt.tight_layout()
plt.savefig('figure9_hourly_error_analysis.png', dpi=300, bbox_inches='tight')
plt.savefig('figure9_hourly_error_analysis.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure9_hourly_error_analysis.png/pdf saved")

# Best model (Hybrid)
best_model_name = 'Hybrid'
best_pred = all_predictions[best_model_name]

fig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=600)

# 1. Prediction vs Actual (detailed)
ax1 = axes[0, 0]
ax1.plot(test_dates, y_test_actual, 'b-', linewidth=2, label='Actual', zorder=5)
ax1.plot(test_dates, best_pred, 'r--', linewidth=2, label='Prediction', zorder=4)
ax1.fill_between(test_dates, y_test_actual, best_pred, alpha=0.3, color='gray', label='Error Area')
ax1.set_xlabel('Date')
ax1.set_ylabel('Temperature (Â°C)')
ax1.set_title(f'(a) {best_model_name} - Actual vs Prediction', fontweight='bold')
ax1.legend()

# 2. Scatter plot (large)
ax2 = axes[0, 1]
ax2.scatter(y_test_actual, best_pred, alpha=0.6, color=COLORS[best_model_name], s=40, edgecolors='white')
min_val, max_val = min(y_test_actual.min(), best_pred.min()), max(y_test_actual.max(), best_pred.max())
ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='y = x')

# Regression
slope, intercept, r_value, _, _ = stats.linregress(y_test_actual, best_pred)
line_x = np.array([min_val, max_val])
ax2.plot(line_x, slope * line_x + intercept, 'b-', linewidth=1.5,
         label=f'Regression: y = {slope:.3f}x + {intercept:.3f}')

r2 = r2_score(y_test_actual, best_pred)
mae = mean_absolute_error(y_test_actual, best_pred)
rmse = np.sqrt(mean_squared_error(y_test_actual, best_pred))

textstr = f'RÂ² = {r2:.4f}\nMAE = {mae:.4f}Â°C\nRMSE = {rmse:.4f}Â°C'
ax2.text(0.05, 0.95, textstr, transform=ax2.transAxes, fontsize=11, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8), fontweight='bold')

ax2.set_xlabel('Actual Temperature (Â°C)')
ax2.set_ylabel('Predicted Temperature (Â°C)')
ax2.set_title(f'(b) {best_model_name} - Scatter Plot', fontweight='bold')
ax2.legend(loc='lower right')
ax2.set_aspect('equal', adjustable='box')

# 3. Residual plot
ax3 = axes[1, 0]
errors = y_test_actual - best_pred
ax3.scatter(best_pred, errors, alpha=0.6, color=COLORS[best_model_name], s=30)
ax3.axhline(y=0, color='red', linestyle='--', linewidth=2)
ax3.axhline(y=errors.mean(), color='blue', linestyle=':', linewidth=1.5,
            label=f'Mean: {errors.mean():.4f}')
ax3.axhline(y=errors.mean() + 2*errors.std(), color='gray', linestyle='--', alpha=0.5)
ax3.axhline(y=errors.mean() - 2*errors.std(), color='gray', linestyle='--', alpha=0.5,
            label=f'Â±2Ïƒ: {2*errors.std():.3f}')
ax3.set_xlabel('Predicted Temperature (Â°C)')
ax3.set_ylabel('Residual (Â°C)')
ax3.set_title(f'(c) {best_model_name} - Residual Analysis', fontweight='bold')
ax3.legend()

# 4. Q-Q Plot
ax4 = axes[1, 1]
stats.probplot(errors, dist="norm", plot=ax4)
ax4.set_title(f'(d) {best_model_name} - Q-Q Plot (Normality)', fontweight='bold')
ax4.get_lines()[0].set_markerfacecolor(COLORS[best_model_name])
ax4.get_lines()[0].set_markersize(5)

plt.tight_layout()
plt.savefig('figure10_best_model_analysis.png', dpi=300, bbox_inches='tight')
plt.savefig('figure10_best_model_analysis.pdf', bbox_inches='tight')
plt.show()
print("âœ… figure10_best_model_analysis.png/pdf saved")

print("=" * 70)
print("TABLO 5: Ä°STATÄ°STÄ°KSEL TEST SONUÃ‡LARI")
print("=" * 70)

statistical_tests = []

for model_name, pred in all_predictions.items():
    errors = y_test_actual - pred

    # Normallik testi (Shapiro-Wilk)
    if len(errors) > 5000:
        shapiro_stat, shapiro_p = stats.shapiro(errors[:5000])
    else:
        shapiro_stat, shapiro_p = stats.shapiro(errors)

    # Durbin-Watson (otokorelasyon)
    from statsmodels.stats.stattools import durbin_watson
    dw_stat = durbin_watson(errors)

    # Mean ve Std
    mean_err = errors.mean()
    std_err = errors.std()

    # Skewness ve Kurtosis
    skew = stats.skew(errors)
    kurt = stats.kurtosis(errors)

    statistical_tests.append({
        'Model': model_name,
        'Hata Ort.': round(mean_err, 4),
        'Hata Std.': round(std_err, 4),
        'Ã‡arpÄ±klÄ±k': round(skew, 4),
        'BasÄ±klÄ±k': round(kurt, 4),
        'Shapiro W': round(shapiro_stat, 4),
        'Shapiro p': round(shapiro_p, 4),
        'Durbin-Watson': round(dw_stat, 4)
    })

stats_test_df = pd.DataFrame(statistical_tests)
stats_test_df = stats_test_df.sort_values('Hata Std.').reset_index(drop=True)

print(stats_test_df.to_string(index=False))

stats_test_df.to_csv('table5_statistical_tests.csv', index=False)
print("\nâœ… table5_statistical_tests.csv kaydedildi")

print("\nðŸ“Š Yorum:")
print("â€¢ Durbin-Watson â‰ˆ 2: Otokorelasyon yok (ideal)")
print("â€¢ Durbin-Watson < 1.5: Pozitif otokorelasyon var")
print("â€¢ Shapiro p > 0.05: Hatalar normal daÄŸÄ±lÄ±mlÄ±")

print("=" * 70)
print("TABLO 6: MODEL KARMAÅžIKLIK KARÅžILAÅžTIRMASI")
print("=" * 70)

model_complexity = pd.DataFrame({
    'Model': ['Prophet', 'SARIMA', 'Random Forest', 'XGBoost', 'CatBoost', 'Hybrid (Stacking)'],
    'Tip': ['Aditif', 'ARIMA', 'Ensemble', 'Boosting', 'Boosting', 'Stacking'],
    'Parametre SayÄ±sÄ±': ['~20', '~10', '~200 aÄŸaÃ§', '~300 aÄŸaÃ§', '~500 iter', '~3 model'],
    'EÄŸitim SÃ¼resi': ['Orta', 'YÃ¼ksek', 'DÃ¼ÅŸÃ¼k', 'DÃ¼ÅŸÃ¼k', 'DÃ¼ÅŸÃ¼k', 'YÃ¼ksek'],
    'Yorumlanabilirlik': ['YÃ¼ksek', 'Orta', 'Orta', 'DÃ¼ÅŸÃ¼k', 'DÃ¼ÅŸÃ¼k', 'DÃ¼ÅŸÃ¼k'],
    'Lag Feature KullanÄ±mÄ±': ['HayÄ±r', 'Otomatik', 'Evet', 'Evet', 'Evet', 'Evet'],
    'Exogenous DeÄŸiÅŸken': ['Evet', 'SÄ±nÄ±rlÄ±', 'Evet', 'Evet', 'Evet', 'Evet']
})

print(model_complexity.to_string(index=False))

model_complexity.to_csv('table6_model_complexity.csv', index=False)
print("\nâœ… table6_model_complexity.csv kaydedildi")

print("=" * 70)
print("ðŸ“ OLUÅžTURULAN DOSYALAR")
print("=" * 70)

import os

files_created = {
    'Tablolar (CSV)': [
        'table1_descriptive_stats.tex',
        'table2_dataset_info.csv',
        'table3_model_performance.csv',
        'table4_feature_importance.csv',
        'table5_statistical_tests.csv',
        'table6_model_complexity.csv'
    ],
    'Åžekiller (PNG/PDF)': [
        'figure1_time_series_overview',
        'figure2_seasonality_analysis',
        'figure3_correlation_matrix',
        'figure4_model_predictions',
        'figure5_scatter_plots',
        'figure6_error_distributions',
        'figure7_performance_comparison',
        'figure8_feature_importance',
        'figure9_hourly_error_analysis',
        'figure10_best_model_analysis'
    ]
}

for category, files in files_created.items():
    print(f"\nðŸ“‚ {category}:")
    for f in files:
        if category == 'Åžekiller (PNG/PDF)':
            print(f"   â€¢ {f}.png")
            print(f"   â€¢ {f}.pdf")
        else:
            print(f"   â€¢ {f}")

print("\n" + "=" * 70)
print("âœ… TÃ¼m akademik iÃ§erik oluÅŸturuldu!")
print("=" * 70)

print("=" * 70)
print("ðŸ“ AKADEMÄ°K MAKALE Ã–ZET METNÄ°")
print("=" * 70)

best_r2 = performance_df.iloc[0]['RÂ²']
best_mae = performance_df.iloc[0]['MAE (Â°C)']
best_rmse = performance_df.iloc[0]['RMSE (Â°C)']
best_model = performance_df.iloc[0]['Model']

abstract = f"""
Ã–ZET

Bu Ã§alÄ±ÅŸmada, saatlik sÄ±caklÄ±k tahmini iÃ§in farklÄ± makine Ã¶ÄŸrenmesi ve
zaman serisi modellerinin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi gerÃ§ekleÅŸtirilmiÅŸtir.
Ã‡alÄ±ÅŸmada {len(df):,} adet 10 dakikalÄ±k meteorolojik gÃ¶zlem verisi kullanÄ±lmÄ±ÅŸ
ve bu veriler saatlik ortalamalara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek {len(df_hourly):,} gÃ¶zlem
elde edilmiÅŸtir.

AltÄ± farklÄ± tahmin modeli deÄŸerlendirilmiÅŸtir: Prophet, SARIMA,
Random Forest, XGBoost, CatBoost ve Hibrit Stacking Ensemble.
Model performanslarÄ± MAE, RMSE, RÂ² ve MAPE metrikleri ile Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r.

SonuÃ§lar, {best_model} modelinin en yÃ¼ksek performansÄ± sergilediÄŸini
gÃ¶stermiÅŸtir (RÂ² = {best_r2}, MAE = {best_mae}Â°C, RMSE = {best_rmse}Â°C).
Lag Ã¶zellikleri (t-1, t-6, t-24 sÄ±caklÄ±k deÄŸerleri) ve hareketli ortalamalar
model performansÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rmÄ±ÅŸtÄ±r. Ã–zellik Ã¶nemliliÄŸi analizi,
T_lag_1 (bir saat Ã¶nceki sÄ±caklÄ±k) deÄŸiÅŸkeninin en belirleyici faktÃ¶r
olduÄŸunu ortaya koymuÅŸtur.

Geleneksel zaman serisi modelleri (Prophet, SARIMA) 7 gÃ¼nlÃ¼k tahmin
horizonunda makine Ã¶ÄŸrenmesi modellerine kÄ±yasla dÃ¼ÅŸÃ¼k performans
gÃ¶stermiÅŸtir. Bu durum, lag Ã¶zelliklerinin doÄŸrudan kullanÄ±lamamasÄ±ndan
kaynaklanmaktadÄ±r.

Anahtar Kelimeler: SÄ±caklÄ±k tahmini, makine Ã¶ÄŸrenmesi, zaman serisi,
ensemble learning, meteorolojik tahmin

---

ABSTRACT

This study presents a comparative analysis of various machine learning
and time series models for hourly temperature forecasting. The dataset
comprises {len(df):,} observations at 10-minute intervals, aggregated
into {len(df_hourly):,} hourly observations.

Six prediction models were evaluated: Prophet, SARIMA, Random Forest,
XGBoost, CatBoost, and Hybrid Stacking Ensemble. Model performance was
assessed using MAE, RMSE, RÂ², and MAPE metrics.

Results indicate that the {best_model} model achieved the highest
performance (RÂ² = {best_r2}, MAE = {best_mae}Â°C, RMSE = {best_rmse}Â°C).
Lag features (t-1, t-6, t-24 temperature values) and rolling averages
significantly improved model performance. Feature importance analysis
revealed that T_lag_1 (previous hour temperature) was the most
influential predictor.

Traditional time series models (Prophet, SARIMA) exhibited lower
performance compared to machine learning models for the 7-day forecast
horizon, primarily due to their inability to directly utilize lag features.

Keywords: Temperature forecasting, machine learning, time series,
ensemble learning, meteorological prediction
"""

print(abstract)

# Kaydet
with open('abstract_summary.txt', 'w', encoding='utf-8') as f:
    f.write(abstract)
print("\nâœ… abstract_summary.txt kaydedildi")

